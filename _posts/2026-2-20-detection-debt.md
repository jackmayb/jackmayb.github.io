---
layout: post
title: Detection Debt
---
Stop Counting Rules: Why Detection Debt Is Quietly Killing Your SOC
Every software engineering leader understands the creeping, compounding cost of technical debt. It's the code that's "good enough for now," the patched-together legacy systems, and the undocumented workarounds that eventually slow feature development to a crawl.
But in the cybersecurity world, we have a parallel problem that gets far less airtime, even though the stakes are arguably higher: Detection Debt.
Detection debt is the quiet accumulation of outdated, noisy, broken, or unmaintained detection rules clogging up your Security Operations Center (SOC) pipeline. Left unmanaged, this debt drains analyst time, obscures real threats under a mountain of alerts, and creates a dangerous illusion of security.
Here's why detection debt accumulates, the toll it takes on your team, and how to start paying down the principal.

The Taxonomy of Detection Debt
Detection debt doesn't look the same everywhere. It accumulates in quiet corners of your SIEM or detection platform in several distinct forms:
The Legacy Leftovers — Detections written by engineers who have long since moved on, where the institutional knowledge of why the rule exists walked out the door with them. This also includes rules monitoring legacy software that's barely used or no longer supported. They sit there like furniture from a previous tenant — nobody remembers buying it, and nobody wants to be the one to throw it out.
The Silent Failures — Detections that look active but are actually matching on nothing. Maybe the underlying log schema changed during a platform upgrade. Maybe environmental drift — a cloud migration, a new OS deployment, an EDR agent update — broke the rule's logic without triggering an error. These are the most dangerous because they don't announce themselves. Consider a rule designed to detect suspicious service creation events by matching on EventCode=7045 in your Windows System logs. If your organization migrates to a new EDR platform that ships service events under a different schema or field name, that rule silently goes dark. It still shows "enabled" in your console. It just never fires again.
The Noise Generators — Rules that haven't been tuned in months, are known to have high false-positive rates, or are generating alerts that analysts have quietly learned to ignore. These are the rules that make triage feel like panning for gold in a landfill.
The Copy-Paste Trap — Community rules, open-source Sigma content, or vendor-supplied threat intelligence (often tied to old TTPs or retired campaigns) that were dropped into the environment verbatim without ever being adapted to your specific infrastructure, naming conventions, or baseline activity.

The Operational Toll on the SOC
Every piece of detection debt creates a tangible drag on daily operations, and the costs are felt most acutely by the people closest to the alerts.
Analyst Burnout. Every false positive generated by a stale rule is analyst time burned. It compounds alert fatigue, and when critical alerts land in a queue already overflowing with noise, the odds of something getting missed go up dramatically.
Onboarding Nightmares. Bringing new analysts up to speed becomes exponentially harder when they have to navigate a massive library of undocumented, half-functioning rules. Instead of learning the threat landscape, they spend their first months learning which alerts to ignore — and that knowledge is almost never written down.
Erosion of Trust. When the detection pipeline cries wolf too often, analysts naturally lose faith in the system. Triage slows down. Alert prioritization becomes unreliable. And eventually, you end up in the worst possible state: a team that has been conditioned to assume alerts aren't worth investigating.

The Most Dangerous Symptom: False Confidence
The daily operational pain is bad enough, but the most insidious consequence of detection debt isn't the wasted time — it's the business risk it conceals.
When leadership looks at a dashboard showing 500 active detection rules, they assume broad, robust protection. The reality is that a significant percentage of those rules might be stale, silently broken, or so noisy that analysts have learned to tune them out mentally. This highlights a critical distinction that every security team needs to internalize: detection count is not detection capability. A high count of active rules is a vanity metric. Actual detection capability — the ability to reliably surface real threats and drive meaningful response — is what stops breaches.
If you can't answer the question "When was the last time this rule generated a true positive that led to an actionable investigation?", then you don't know whether that rule is protecting you or just taking up space.

Why Does It Accumulate?
Detection debt isn't born from negligence. It's almost always the result of structural issues and incentive misalignment within the security organization:
Build Culture Over Maintain Culture. Detection engineers are heavily incentivized to create new coverage. That's the visible, reportable, "slides well in a quarterly review" kind of work. Retiring, refactoring, or deleting old rules? That rarely shows up in anyone's performance goals, even though it's arguably just as valuable.
The Fear of Deletion. There's a heavy psychological cost to turning off a detection. Nobody wants to be the person who disabled the alert that would have caught tomorrow's ransomware incident. So the rules just stay active, accumulating like a junk drawer nobody wants to open.
Employee Churn. When the creator of a complex, undocumented detection leaves the company, the remaining team inherits a black box they're afraid to touch. Without context on the original threat model, the data source dependencies, or the tuning decisions that went into the rule, it becomes effectively unmaintainable — but also undeletable.

Paying Down the Principal
You can't declare bankruptcy on detection debt, but you can start actively managing it. The key is to move beyond generic "tune your rules" advice and build practices that make debt management a structural part of your detection engineering lifecycle.
Lead With Your Hunts
If your organization runs a threat hunting program, you already have one of the most powerful tools for identifying detection debt — you just might not be using it that way. Every threat hunt is an opportunity to simultaneously audit your existing detection coverage.
Here's what that looks like in practice: when a hunt targets a specific technique (say, lateral movement via WMI), the hunt team shouldn't just be looking for evidence of that activity in the environment. They should also be asking: "Do we have a detection rule for this? If so, did it fire during our hunt window? If we simulated or found real activity, did the rule catch it?" If the answer is no, you've just identified a silent failure — and that finding should be formally documented alongside the hunt's other results.
Building this "detection validation" step into your hunt methodology turns every hunt into a two-for-one: you get threat discovery and coverage auditing in the same engagement.
Enforce Strict Metadata Standards
Every detection in your pipeline should carry a minimum set of metadata: an assigned owner, a creation date, a list of data source dependencies, a "last validated" date, and a brief description of the threat model it addresses. This isn't bureaucracy — it's the difference between a maintainable detection library and a graveyard of mystery rules. When a rule has no owner and no documentation, it becomes untouchable, and untouchable rules are how silent failures are born.
Build a Deprecation Pipeline
Most teams have a well-defined process for creating and deploying new detections. Far fewer have a formal process for retiring them. Build one. A deprecation pipeline should include criteria for when a rule is a candidate for retirement (e.g., no true positives in 90 days, data source no longer ingested, technique superseded by a newer rule), a review step before deactivation, and an archive process so you can recover rules if needed. Making deletion feel safe and reversible lowers the psychological barrier.
Measure Capability, Not Count
Stop reporting on the number of active rules and start tracking metrics that reflect actual detection health. Some starting points:
	•	Fire rate: How often does this rule generate any alert at all? A rule that hasn't fired in six months might be silently broken — or it might be highly specific and valuable. The metric alone doesn't tell you, but it flags rules that need investigation.
	•	True positive rate: Of the alerts this rule generates, what percentage result in a real investigation? A rule with a 2% true positive rate is a noise generator and a candidate for aggressive tuning or retirement.
	•	Last actionable alert date: When was the last time this rule led to a meaningful security action? This is the single most revealing metric for detection health.
	•	Data source dependency status: Are the log sources this rule depends on still being ingested at the expected volume and schema? This catches silent failures before they go unnoticed for months.
Schedule It Like Maintenance
Move away from tuning rules "when we get around to it." Detection reviews need to be a formalized cadence — quarterly at minimum, monthly if your environment changes frequently. Treat it like patching: it's not glamorous, but skipping it has compounding consequences.

Detection Debt as a Maturity Indicator
How a team handles detection debt reveals more about its operational maturity than how many rules it can build in a quarter. Early-stage security programs are focused purely on expanding coverage, and that's appropriate — you have to build the foundation. But mature programs recognize that curation, maintenance, and strategic pruning aren't just housekeeping. They're core operational disciplines.
Just like financial or technical debt, detection debt compounds interest. Every quarter you don't address it, the operational cost rises and the risk of a hidden gap grows.
So stop counting your rules. If you can't tell me which 10% of your detection library you'd confidently delete tomorrow, you've already got a debt problem worth solving.
